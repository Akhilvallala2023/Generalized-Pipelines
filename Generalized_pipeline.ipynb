{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQeBYVSk1/OuXoJ1+6xjd9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akhilvallala2023/Generalized-Pipelines/blob/main/Generalized_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the user to enter their GitHub token securely\n",
        "import getpass\n",
        "\n",
        "# Prompt for the token\n",
        "token = getpass.getpass(\"Enter your GitHub token: \")\n",
        "\n",
        "# Clone the repository using the token\n",
        "!git clone https://{token}@github.com/Akhilvallala2023/Generalized-Pipelines.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z21iKXU84_bx",
        "outputId": "8aaeb3e5-0b7e-4076-879a-bd2fdefe17f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Generalized-Pipelines'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWgfL4Q8g_lT",
        "outputId": "aab4e6e0-4450-49d0-a2a0-b5aa2cd4fdc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.3.15)\n",
            "Collecting openai<2.0.0,>=1.54.0 (from langchain_openai)\n",
            "  Downloading openai-1.54.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (0.1.137)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_openai) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
            "Downloading langchain_openai-0.2.6-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.54.3-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain_openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.52.2\n",
            "    Uninstalling openai-1.52.2:\n",
            "      Successfully uninstalled openai-1.52.2\n",
            "Successfully installed langchain_openai-0.2.6 openai-1.54.3 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade langchain_openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resume"
      ],
      "metadata": {
        "id": "7hSnTTbEl8Yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Prompt the user to enter the OpenAI API key\n",
        "api_key = input(\"Please enter your OpenAI API key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Confirm that the key has been set\n",
        "print(\"OpenAI API key has been set.\")\n",
        "\n",
        "# Initialize the model\n",
        "model = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "# Step 1: Define General Agent Templates\n",
        "\n",
        "# Task Analysis Agent - identifies task-specific requirements\n",
        "task_prompt = ChatPromptTemplate.from_template(\"Analyze the task: {task}\")\n",
        "task_analysis_chain = LLMChain(prompt=task_prompt, llm=model)\n",
        "\n",
        "# Configuration Agent - configures agents based on task analysis\n",
        "config_prompt = ChatPromptTemplate.from_template(\"Based on analysis {analysis}, configure agents\")\n",
        "config_chain = LLMChain(prompt=config_prompt, llm=model)\n",
        "\n",
        "# Execution Agent for generating resume content\n",
        "resume_generation_prompt = ChatPromptTemplate.from_template(\"Create a professional resume for the user with the following details: {user_input}\")\n",
        "resume_generation_chain = LLMChain(prompt=resume_generation_prompt, llm=model)\n",
        "\n",
        "# ATS Scoring Agent for evaluating resume against job description\n",
        "ats_score_prompt = ChatPromptTemplate.from_template(\"Evaluate the resume against the job description and provide an ATS score.\")\n",
        "ats_score_chain = LLMChain(prompt=ats_score_prompt, llm=model)\n",
        "\n",
        "# Step 2: Agent Orchestrator for Dynamic Task Assembly\n",
        "class DynamicAgentOrchestrator:\n",
        "    def __init__(self, task_description: str, user_input: str = None, job_description: str = None):\n",
        "        self.task_description = task_description\n",
        "        self.user_input = user_input\n",
        "        self.job_description = job_description\n",
        "        self.agents = {}\n",
        "\n",
        "    def analyze_task(self):\n",
        "        # Analyze the task and determine required agents\n",
        "        analysis_result = task_analysis_chain.invoke({\"task\": self.task_description})\n",
        "        return analysis_result\n",
        "\n",
        "    def configure_agents(self, analysis_result):\n",
        "        # Configure agents dynamically based on task analysis\n",
        "        config_result = config_chain.invoke({\"analysis\": analysis_result})\n",
        "\n",
        "        # Dynamically define agents based on task requirements\n",
        "        if \"resume\" in self.task_description.lower():\n",
        "            self.agents[\"resume_generator\"] = resume_generation_chain\n",
        "            self.agents[\"ats_scorer\"] = ats_score_chain\n",
        "\n",
        "    def run_agents(self):\n",
        "        # Run the dynamically configured agents\n",
        "\n",
        "        # Execute resume generation if configured\n",
        "        resume_output = None\n",
        "        if \"resume_generator\" in self.agents:\n",
        "            resume_output = self.agents[\"resume_generator\"].invoke({\"user_input\": self.user_input})\n",
        "\n",
        "        # Execute ATS scoring if configured\n",
        "        ats_score_output = None\n",
        "        if \"ats_scorer\" in self.agents and resume_output:\n",
        "            ats_score_output = self.agents[\"ats_scorer\"].invoke({\"output\": resume_output, \"job_description\": self.job_description})\n",
        "\n",
        "        # Collect results\n",
        "        return {\n",
        "            \"generated_resume\": resume_output,\n",
        "            \"ats_score\": ats_score_output\n",
        "        }\n",
        "\n",
        "# Step 3: Run Dynamic Task Workflow\n",
        "def execute_dynamic_task(task_description: str, user_input: str, job_description: str):\n",
        "    # Initialize the orchestrator with the task, user input, and job description\n",
        "    orchestrator = DynamicAgentOrchestrator(task_description, user_input, job_description)\n",
        "\n",
        "    # Step 1: Task Analysis\n",
        "    analysis_result = orchestrator.analyze_task()\n",
        "\n",
        "    # Step 2: Agent Configuration\n",
        "    orchestrator.configure_agents(analysis_result)\n",
        "\n",
        "    # Step 3: Execute Agents and Collect Results\n",
        "    results = orchestrator.run_agents()\n",
        "\n",
        "    # Print only the resume and ATS score\n",
        "    print(json.dumps({\n",
        "        \"generated_resume\": results[\"generated_resume\"],\n",
        "        \"ats_score\": results[\"ats_score\"]\n",
        "    }, indent=2))\n",
        "\n",
        "# Example usage\n",
        "task_description = \"Create a resume for the user.\"\n",
        "user_input = \"User has 5 years experience in software development, skilled in Python, AI, and data science.\"\n",
        "job_description = \"Looking for a software developer with experience in Python and machine learning.\"\n",
        "\n",
        "# Run the task\n",
        "execute_dynamic_task(task_description, user_input, job_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57iOdYNThYzk",
        "outputId": "0615f223-b80a-43c7-f6ac-2f9a5ab1686a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"generated_resume\": {\n",
            "    \"user_input\": \"User has 5 years experience in software development, skilled in Python, AI, and data science.\",\n",
            "    \"text\": \"[Your Name]\\n[Your Address]\\n[Your City, State, Zip]\\n[Your Email]\\n[Your Phone Number]\\n\\nObjective:\\nHighly motivated and experienced software developer with 5 years of experience in the technology industry, seeking to utilize my skills in Python, AI, and data science to innovate and excel in a challenging environment.\\n\\nSkills:\\n\\n1. Proficient in Python and various Python libraries.\\n2. Extensive experience in AI and data science.\\n3. Strong understanding of machine learning algorithms.\\n4. Excellent problem-solving abilities.\\n5. Strong interpersonal and communication skills.\\n6. Profound knowledge of data structures and algorithms.\\n7. Able to work in a team or individually.\\n8. Excellent attention to detail.\\n\\nWork Experience:\\n\\nSoftware Developer | [Company Name] | [City, State] | [Dates]\\n\\n1. Collaborated with a team of software developers to design, develop, and maintain software applications.\\n2. Implemented machine learning algorithms to improve software efficiency and performance.\\n3. Utilized Python to automate tasks and processes, reducing manual intervention by 40%.\\n4. Worked on AI projects and made significant contributions to the development of innovative features.\\n5. Led data science projects and successfully interpreted complex data to provide actionable business insights.\\n6. Conducted code reviews, unit testing, and debugging to improve software quality.\\n\\nSoftware Developer Intern | [Company Name] | [City, State] | [Dates]\\n\\n1. Assisted in the development and maintenance of software applications.\\n2. Developed Python scripts for automating tasks.\\n3. Participated in AI research and development projects.\\n4. Assisted in data analysis and interpretation.\\n\\nEducation:\\n\\nBachelor of Science in Computer Science | [University Name] | [City, State] | [Graduation Date]\\n\\nCertifications:\\n\\n1. Certified Professional in Python Programming.\\n2. Certified Expert in Data Science.\\n3. Certified Professional in AI.\\n\\nReferences:\\n\\nAvailable upon request.\\n\\nI am excited about the opportunity to bring my unique blend of skills and experience to a dynamic and innovative software development team. I am confident that my strong technical skills, as well as my passion for the latest industry trends, make me a strong candidate for a variety of software development roles. I am eager to continue growing my skills and contributing to a team environment.\"\n",
            "  },\n",
            "  \"ats_score\": {\n",
            "    \"output\": {\n",
            "      \"user_input\": \"User has 5 years experience in software development, skilled in Python, AI, and data science.\",\n",
            "      \"text\": \"[Your Name]\\n[Your Address]\\n[Your City, State, Zip]\\n[Your Email]\\n[Your Phone Number]\\n\\nObjective:\\nHighly motivated and experienced software developer with 5 years of experience in the technology industry, seeking to utilize my skills in Python, AI, and data science to innovate and excel in a challenging environment.\\n\\nSkills:\\n\\n1. Proficient in Python and various Python libraries.\\n2. Extensive experience in AI and data science.\\n3. Strong understanding of machine learning algorithms.\\n4. Excellent problem-solving abilities.\\n5. Strong interpersonal and communication skills.\\n6. Profound knowledge of data structures and algorithms.\\n7. Able to work in a team or individually.\\n8. Excellent attention to detail.\\n\\nWork Experience:\\n\\nSoftware Developer | [Company Name] | [City, State] | [Dates]\\n\\n1. Collaborated with a team of software developers to design, develop, and maintain software applications.\\n2. Implemented machine learning algorithms to improve software efficiency and performance.\\n3. Utilized Python to automate tasks and processes, reducing manual intervention by 40%.\\n4. Worked on AI projects and made significant contributions to the development of innovative features.\\n5. Led data science projects and successfully interpreted complex data to provide actionable business insights.\\n6. Conducted code reviews, unit testing, and debugging to improve software quality.\\n\\nSoftware Developer Intern | [Company Name] | [City, State] | [Dates]\\n\\n1. Assisted in the development and maintenance of software applications.\\n2. Developed Python scripts for automating tasks.\\n3. Participated in AI research and development projects.\\n4. Assisted in data analysis and interpretation.\\n\\nEducation:\\n\\nBachelor of Science in Computer Science | [University Name] | [City, State] | [Graduation Date]\\n\\nCertifications:\\n\\n1. Certified Professional in Python Programming.\\n2. Certified Expert in Data Science.\\n3. Certified Professional in AI.\\n\\nReferences:\\n\\nAvailable upon request.\\n\\nI am excited about the opportunity to bring my unique blend of skills and experience to a dynamic and innovative software development team. I am confident that my strong technical skills, as well as my passion for the latest industry trends, make me a strong candidate for a variety of software development roles. I am eager to continue growing my skills and contributing to a team environment.\"\n",
            "    },\n",
            "    \"job_description\": \"Looking for a software developer with experience in Python and machine learning.\",\n",
            "    \"text\": \"Sorry, as an AI, I don't have the ability to evaluate a resume against a job description or provide an ATS (Applicant Tracking System) score. This process usually involves analyzing specific keywords, skills, experiences, and other information in a resume and comparing them to the requirements in a job description, which is something best done by a professional HR or a specialized software.\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Working Pipeline (done)"
      ],
      "metadata": {
        "id": "_DcoEOqy6JYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Prompt the user to enter the OpenAI API key\n",
        "api_key = input(\"Please enter your OpenAI API key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Confirm that the key has been set\n",
        "print(\"OpenAI API key has been set.\")\n",
        "\n",
        "# Initialize the model (use GPT-3.5 or GPT-4)\n",
        "model = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "# Define an Agent class where each agent's behavior is defined by a prompt\n",
        "class Agent:\n",
        "    def __init__(self, name: str, prompt: str):\n",
        "        self.name = name\n",
        "        # Use '{input}' as a placeholder in the prompt to ensure the data is passed correctly\n",
        "        formatted_prompt = f\"{prompt} Input: {{input}}\"\n",
        "        self.prompt_template = ChatPromptTemplate.from_template(formatted_prompt)\n",
        "        self.chain = LLMChain(prompt=self.prompt_template, llm=model)\n",
        "\n",
        "    def run(self, data):\n",
        "        print(f\"\\nRunning agent '{self.name}'...\")\n",
        "        # Pass 'data' as 'input' in the invocation\n",
        "        response = self.chain.invoke({\"input\": data})\n",
        "        # Ensure output key is 'output' for clarity and only the essential data is passed\n",
        "        return {\"input\": data, \"output\": response[\"text\"]}\n",
        "\n",
        "# Define a Pipeline to manage multiple agents\n",
        "class Pipeline:\n",
        "    def __init__(self):\n",
        "        self.agents = []\n",
        "\n",
        "    def add_agent(self, agent: Agent):\n",
        "        self.agents.append(agent)\n",
        "        print(f\"Agent '{agent.name}' added to the pipeline.\")\n",
        "\n",
        "    def run_pipeline(self, data):\n",
        "        print(\"\\nStarting pipeline execution...\\n\")\n",
        "        # Pass 'data' through each agent in the pipeline sequentially\n",
        "        for i, agent in enumerate(self.agents, start=1):\n",
        "            # The output of each agent becomes the input for the next agent\n",
        "            result = agent.run(data)\n",
        "            data = result[\"output\"]  # Only pass the 'output' to the next agent\n",
        "            # Display the output of each agent with clear formatting\n",
        "            print(f\"Output after Agent {i} ('{agent.name}'): {result}\\n\")\n",
        "            time.sleep(1)  # Adding a slight delay for readability\n",
        "        print(\"Pipeline execution completed.\")\n",
        "        # Final output after passing through all agents\n",
        "        return data\n",
        "\n",
        "# Helper function to create a new agent\n",
        "def create_agent():\n",
        "    name = input(\"Enter the name of the new agent: \")\n",
        "    prompt = input(\"Describe the agent's task in natural language (e.g., 'Translate the English text to Telugu'): \")\n",
        "    return Agent(name, prompt)\n",
        "\n",
        "# Main loop to manage pipeline creation\n",
        "def main():\n",
        "    pipeline = Pipeline()\n",
        "\n",
        "    while True:\n",
        "        if len(pipeline.agents) >= 1:\n",
        "            choice = input(\"\\nWould you like to add a new agent or run the pipeline? (add/run/exit): \").strip().lower()\n",
        "        else:\n",
        "            choice = 'add'  # Force adding the first agent\n",
        "\n",
        "        if choice == 'add':\n",
        "            agent = create_agent()\n",
        "            pipeline.add_agent(agent)\n",
        "        elif choice == 'run' and len(pipeline.agents) >= 1:\n",
        "            # Allow the pipeline to run even if there's only one agent\n",
        "            initial_data = input(\"Enter initial data for the pipeline: \")\n",
        "            pipeline.run_pipeline(initial_data)\n",
        "        elif choice == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid option. Please enter 'add', 'run', or 'exit'.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D8lPzhW1uRn",
        "outputId": "e1f63482-2107-49dd-fcda-a591fffb967c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your OpenAI API key: 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\n",
            "OpenAI API key has been set.\n",
            "Enter the name of the new agent: hackathonIDEAS\n",
            "Describe the agent's task in natural language (e.g., 'Translate the English text to Telugu'): You are a specialist in winning hackathon, when given a problem statement you have to generate proper hackathon pitch with innovative solution.\n",
            "Agent 'hackathonIDEAS' added to the pipeline.\n",
            "\n",
            "Would you like to add a new agent or run the pipeline? (add/run/exit): run\n",
            "Enter initial data for the pipeline: langchain hackathon, The need to use multi agent to solve SDLC\n",
            "\n",
            "Starting pipeline execution...\n",
            "\n",
            "\n",
            "Running agent 'hackathonIDEAS'...\n",
            "Output after Agent 1 ('hackathonIDEAS'): {'input': 'langchain hackathon, The need to use multi agent to solve SDLC', 'output': \"Title: SDLC Optimization with Multi-Agent Systems – The Langchain Solution\\n\\nPitch:\\n\\nImagine a world where the Software Development Life Cycle (SDLC) is seamless, efficient, and optimized for productivity. No more time wasted in the planning, designing, coding, testing, and deployment stages. We're here to introduce Langchain, a revolutionary solution to overcome the challenges in SDLC using multi-agent systems.\\n\\nThe current SDLC model lacks the ability to adapt quickly to changes, resulting in inefficiencies and errors. We propose a novel solution, Langchain, which leverages multi-agent systems to facilitate a dynamic, adaptive, and efficient SDLC.\\n\\nOur solution involves the use of intelligent agents, each specialized in different stages of the SDLC. These agents can communicate, collaborate, and negotiate with each other to ensure the smooth progression of the software development process. \\n\\nFor instance, the Planning Agent can gather and analyze requirements, and then pass this information to the Design Agent. The Design agent can then create a suitable software architecture and pass it to the Coding Agent. These interactions continue until the software is deployed and maintained. \\n\\nThe beauty of Langchain lies in its inherent flexibility. Each agent can independently adapt to changing requirements or unexpected problems, resulting in a software development process that is not only faster but also more reliable and effective. \\n\\nLangchain also incorporates a learning mechanism, allowing each agent to learn from its past experiences and improve its performance over time. This means that the more you use Langchain, the better it gets at managing your SDLC.\\n\\nInnovative, adaptive, and efficient, Langchain redefines the way we approach SDLC. It not only reduces the time and resources needed for software development but also significantly improves the quality of the final product.\\n\\nLangchain is the future of SDLC. Let's embrace this future, together.\"}\n",
            "\n",
            "Pipeline execution completed.\n",
            "\n",
            "Would you like to add a new agent or run the pipeline? (add/run/exit): exit\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input file to the pipeline"
      ],
      "metadata": {
        "id": "nTM6RMhz6lTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-pptx PyMuPDF python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaaIQlu6HG_u",
        "outputId": "73af2aff-4e23-4c20-caa6-81e1e819c903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (10.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-docx, PyMuPDF, python-pptx\n",
            "Successfully installed PyMuPDF-1.24.13 XlsxWriter-3.2.0 python-docx-1.1.2 python-pptx-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import os\n",
        "import time\n",
        "from pptx import Presentation  # For reading .pptx files\n",
        "import fitz  # For reading .pdf files (PyMuPDF)\n",
        "from docx import Document  # For reading .docx files\n",
        "\n",
        "# Prompt the user to enter the OpenAI API key\n",
        "api_key = input(\"Please enter your OpenAI API key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Confirm that the key has been set\n",
        "print(\"OpenAI API key has been set.\")\n",
        "\n",
        "# Initialize the model (use GPT-3.5 or GPT-4)\n",
        "model = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "# Define an Agent class where each agent's behavior is defined by a prompt\n",
        "class Agent:\n",
        "    def __init__(self, name: str, prompt: str):\n",
        "        self.name = name\n",
        "        # Use '{input}' as a placeholder in the prompt to ensure the data is passed correctly\n",
        "        formatted_prompt = f\"{prompt} Input: {{input}}\"\n",
        "        self.prompt_template = ChatPromptTemplate.from_template(formatted_prompt)\n",
        "        self.chain = LLMChain(prompt=self.prompt_template, llm=model)\n",
        "\n",
        "    def run(self, data):\n",
        "        print(f\"\\nRunning agent '{self.name}'...\")\n",
        "        # Pass 'data' as 'input' in the invocation\n",
        "        response = self.chain.invoke({\"input\": data})\n",
        "        # Ensure output key is 'output' for clarity and only the essential data is passed\n",
        "        return {\"input\": data, \"output\": response[\"text\"]}\n",
        "\n",
        "# Define a Pipeline to manage multiple agents\n",
        "class Pipeline:\n",
        "    def __init__(self):\n",
        "        self.agents = []\n",
        "\n",
        "    def add_agent(self, agent: Agent):\n",
        "        self.agents.append(agent)\n",
        "        print(f\"Agent '{agent.name}' added to the pipeline.\")\n",
        "\n",
        "    def run_pipeline(self, data):\n",
        "        print(\"\\nStarting pipeline execution...\\n\")\n",
        "        # Pass 'data' through each agent in the pipeline sequentially\n",
        "        for i, agent in enumerate(self.agents, start=1):\n",
        "            # The output of each agent becomes the input for the next agent\n",
        "            result = agent.run(data)\n",
        "            data = result[\"output\"]  # Only pass the 'output' to the next agent\n",
        "            # Display the output of each agent with clear formatting\n",
        "            print(f\"Output after Agent {i} ('{agent.name}'): {result}\\n\")\n",
        "            time.sleep(1)  # Adding a slight delay for readability\n",
        "        print(\"Pipeline execution completed.\")\n",
        "        # Final output after passing through all agents\n",
        "        return data\n",
        "\n",
        "# Helper function to create a new agent\n",
        "def create_agent():\n",
        "    name = input(\"Enter the name of the new agent: \")\n",
        "    prompt = input(\"Describe the agent's task in natural language (e.g., 'Translate the English text to Telugu'): \")\n",
        "    return Agent(name, prompt)\n",
        "\n",
        "# Function to read different types of files and return their content\n",
        "def read_file(file_path):\n",
        "    print(\"file_path =\",file_path)\n",
        "    extension = os.path.splitext(file_path)[-1].lower()\n",
        "\n",
        "    try:\n",
        "        if extension == \".txt\":\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "                return file.read()\n",
        "\n",
        "        elif extension == \".pptx\":\n",
        "            presentation = Presentation(file_path)\n",
        "            text = \"\"\n",
        "            for slide in presentation.slides:\n",
        "                for shape in slide.shapes:\n",
        "                    if hasattr(shape, \"text\"):\n",
        "                        text += shape.text + \"\\n\"\n",
        "            return text\n",
        "\n",
        "        elif extension == \".pdf\":\n",
        "            text = \"\"\n",
        "            pdf_document = fitz.open(file_path)\n",
        "            for page_num in range(pdf_document.page_count):\n",
        "                page = pdf_document[page_num]\n",
        "                text += page.get_text(\"text\") + \"\\n\"\n",
        "            pdf_document.close()\n",
        "            return text\n",
        "\n",
        "        elif extension == \".docx\":\n",
        "            doc = Document(file_path)\n",
        "            text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
        "            return text\n",
        "\n",
        "        else:\n",
        "            print(f\"Unsupported file type: {extension}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_pipeline_input():\n",
        "    input_type = input(\"Enter input type (text/file): \").strip().lower()\n",
        "\n",
        "    if input_type == \"text\":\n",
        "        # Text input\n",
        "        return input(\"Enter text input: \")\n",
        "    elif input_type == \"file\":\n",
        "        # File input\n",
        "        file_path = input(\"Enter the file path: \").strip()\n",
        "        return read_file(file_path)\n",
        "    else:\n",
        "        print(\"Invalid input type. Please enter 'text' or 'file'.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Main loop to manage pipeline creation\n",
        "def main():\n",
        "    pipeline = Pipeline()\n",
        "\n",
        "    while True:\n",
        "        if len(pipeline.agents) >= 1:\n",
        "            choice = input(\"\\nWould you like to add a new agent or run the pipeline? (add/run/exit): \").strip().lower()\n",
        "        else:\n",
        "            choice = 'add'  # Force adding the first agent\n",
        "\n",
        "        if choice == 'add':\n",
        "            agent = create_agent()\n",
        "            pipeline.add_agent(agent)\n",
        "        elif choice == 'run' and len(pipeline.agents) >= 1:\n",
        "            # Allow the pipeline to run even if there's only one agent\n",
        "            initial_data = get_pipeline_input()\n",
        "            if initial_data is not None:\n",
        "                pipeline.run_pipeline(initial_data)\n",
        "            else:\n",
        "                print(\"No valid input provided. Pipeline execution aborted.\")\n",
        "        elif choice == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid option. Please enter 'add', 'run', or 'exit'.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "tHW94BhvFDIM",
        "outputId": "e49fac45-d3a0-41b0-856e-b2359b2d9ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-dde00fe0ed67>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Prompt the user to enter the OpenAI API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter your OpenAI API key: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input file at the agent level"
      ],
      "metadata": {
        "id": "QrLftNDn6xmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making a proper prompt"
      ],
      "metadata": {
        "id": "F26FmZ6E6ek5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#History of pipelines"
      ],
      "metadata": {
        "id": "0tIdsjEl6bX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making pipeline public or Private"
      ],
      "metadata": {
        "id": "v5ek3S8669BO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rating to the pipeline"
      ],
      "metadata": {
        "id": "9wXkI-PN7GtP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-dtQDBVd3arw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}